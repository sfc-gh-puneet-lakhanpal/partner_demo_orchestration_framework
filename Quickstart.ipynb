{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Gateway Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent Gateway is a multi-agent framework that offers native support for Snowflake tools. \n",
    "\n",
    "The system can be configured to work with 3 types of tools:\n",
    "- Cortex Search Tool: For unstructured data analysis, which requires a standard RAG access pattern.\n",
    "- Cortex Analyst Tool: For supporting structured data analysis, which requires a Text2SQL access pattern.\n",
    "- Python Tool: For supporting custom user operations (using 3rd Party API's), which requires calling arbitrary python.\n",
    "\n",
    "This notebook walks through how to configure and run a system with all 3 types of tools. The demo is designed to illustrate how the agent can answer questions that require a divserse combination of tools (RAG,Text2SQL, Python, or a combination).\n",
    "\n",
    "Note that Agent Gateway does not configure the underlying Cortex Search or Cortex Analyst services for the user. Those services must be configured before initializing the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authenticate with Snowpark + set token as environment variable for use by the agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Initialized with db url snowflake://pse_sysadmin:***@SFSEEUROPE-US_WEST_CCARRERO_452/AGENTIC_DB/ORCHESTRATION_FRAMEWORK_SCH?port=443&protocol=https&role=SYSADMIN&warehouse=QUICKSTART_WH .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `TruSession` to prevent this.\n",
      "Set TruLens workspace version tag: [('Statement executed successfully.',)]\n"
     ]
    }
   ],
   "source": [
    "from agent_gateway import Agent\n",
    "from agent_gateway.tools import CortexSearchTool, CortexAnalystTool, PythonTool\n",
    "from agent_gateway import TruAgent\n",
    "from trulens.connectors.snowflake import SnowflakeConnector\n",
    "from snowflake.snowpark import Session\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")\n",
    "connection_parameters = {\n",
    "    \"account\": os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
    "    \"user\": os.getenv(\"SNOWFLAKE_USER\"),\n",
    "    \"password\": os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
    "    \"role\": os.getenv(\"SNOWFLAKE_ROLE\"),\n",
    "    \"warehouse\": os.getenv(\"SNOWFLAKE_WAREHOUSE\"),\n",
    "    \"database\": os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
    "    \"schema\": os.getenv(\"SNOWFLAKE_SCHEMA\"),\n",
    "}\n",
    "\n",
    "snowpark = Session.builder.configs(connection_parameters).create()\n",
    "conn = SnowflakeConnector(**connection_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snowflake Tool Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cortex Search Tool and the Cortex Analyst Tool need to be configured as follows. Note that a connection object is required for each config. In the case below we're using the same connection object for both because the services are both in the same account/database/schema. Users have the option to pass in different connection objects as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_search_config = {\n",
    "        \"service_name\": \"TOPIC_SEARCH\",\n",
    "        \"service_topic\": \"Support case topics\",\n",
    "        \"data_description\": \"Quarterly analysis of support case topics, specifically focusing on the domain of Rider Experience for a specific calendar quarter.\",\n",
    "        \"retrieval_columns\": [\"topic_summary\", \"topic\", \"domain\", \"quarter\", \"case_count\"],\n",
    "        \"snowflake_connection\": snowpark,\n",
    "    }\n",
    "\n",
    "domain_search_config = {\n",
    "    \"service_name\": \"DOMAIN_SEARCH\",\n",
    "    \"service_topic\": \"Overview of main pain points, overall health scores of various topics, notable trends in metrics, and recommendations for areas that need immediate attention. This information is part of a broader document that analyzes support domain health metrics, including case volumes, severity rates, response times, and overall health scores across different domains.\",\n",
    "    \"data_description\": \"Detailed analysis of the Driver Operations, Rider Experience, Corporate and Fleet Accounts, Safety and Security, Driver Operations, Loyalty and Promotions and App Connectivity product domains in different calendar quarters.\",\n",
    "    \"retrieval_columns\": [\"domain_summary\", \"domain\", \"quarter\"],\n",
    "    \"snowflake_connection\": snowpark,\n",
    "}\n",
    "\n",
    "case_search_config = {\n",
    "    \"service_name\": \"CASE_SEARCH\",\n",
    "    \"service_topic\": \"Support ticket details\",\n",
    "    \"data_description\": \"Details of Support tickets on Ride booking, Ride tracking, Rating and feedback, Driver safety, Login authentication, Ride Verification, Background Checks, Incident reporting, Event rides, Expense tracking, Subscription plans, Payment options, Driver matching, Earnings dashboard, Navigation routes, App performance, Notifications, Language support, Emergency Features, Reward program, Promo codes, Corporate rides, Fleet management and Driver Rating Dashboard\",\n",
    "    \"retrieval_columns\": [\"ticket_body\", \"domain\",\"feature\",\"topic\",\"quarter\",\"ticket_id\",\"severity\"],\n",
    "    \"snowflake_connection\": snowpark,\n",
    "}\n",
    "\n",
    "ride_analyst_config = {\n",
    "    \"semantic_model\": \"rides.yaml\",\n",
    "    \"stage\": \"SEMANTIC_YAMLS\",\n",
    "    \"service_topic\": \"Rides related metrics\",\n",
    "    \"data_description\": \"a table with Rides providing a comprehensive summary of ride data, including ride ID, customer and driver information, quarter, timestamp, location, and ride cost allowing for easy analysis and reporting of ride-related activities.\",\n",
    "    \"snowflake_connection\": snowpark,\n",
    "}\n",
    "\n",
    "support_ticket_analyst_config = {\n",
    "    \"semantic_model\": \"support_tickets.yaml\",\n",
    "    \"stage\": \"SEMANTIC_YAMLS\",\n",
    "    \"service_topic\": \"Support tickets related metrics\",\n",
    "    \"data_description\": \"a table with Support Tickets providing a comprehensive summary of support tickets, including customer id, ticket details, and key metrics such as possession time, life time, and health scores.\",\n",
    "    \"snowflake_connection\": snowpark,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Tool Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring a Python Tool for the Agent Gateway requires 1) Python Callable 2) Tool Description (what does the tool do) 3) Output Description (what does the tool output). \n",
    "\n",
    "In the example below we create a NewsTool object that submits a HTTP request to a 3rd Party News API. The python callable is passed into the Python Tool as `news_api_func`.To use the tool below get your free token by signing up for an account at thenewsapi.com or just create your own python function and pass it into the PythonTool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "os.environ[\"NEWS_API_TOKEN\"] = os.getenv(\"NEWS_API_TOKEN\")\n",
    "\n",
    "\n",
    "def html_crawl(url):\n",
    "    response = requests.get(url)\n",
    "    return response.text\n",
    "\n",
    "class NewsTool:\n",
    "    def __init__(self, token, limit) -> None:\n",
    "        self.api_token = token\n",
    "        self.limit = limit\n",
    "\n",
    "    def news_search(self, news_query: str) -> str:\n",
    "        news_request = f\"\"\"https://api.thenewsapi.com/v1/news/all?api_token={self.api_token}&search={news_query}&language=en&limit={self.limit}\"\"\"\n",
    "        response = requests.get(news_request)\n",
    "        json_response = json.loads(response.content)[\"data\"]\n",
    "\n",
    "        return str(json_response)\n",
    "    \n",
    "python_crawler_config = {\n",
    "    \"tool_description\": \"reads the html from a given URL or website\",\n",
    "    \"output_description\": \"html of a webpage\",\n",
    "    \"python_func\": html_crawl,\n",
    "}\n",
    "news_python_config = {\n",
    "    \"tool_description\": \"searches for relevant news based on user query\",\n",
    "    \"output_description\": \"relevant articles\",\n",
    "    \"python_func\": NewsTool(token=os.getenv(\"NEWS_API_TOKEN\"), limit=3).news_search,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the tools have been configured, initialize them and configure the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:AgentGatewayLogger:Cortex Search Tool successfully initialized\n",
      "INFO:AgentGatewayLogger:Cortex Search Tool successfully initialized\n",
      "INFO:AgentGatewayLogger:Cortex Search Tool successfully initialized\n",
      "INFO:AgentGatewayLogger:Cortex Analyst Tool successfully initialized\n",
      "INFO:AgentGatewayLogger:Cortex Analyst Tool successfully initialized\n",
      "INFO:AgentGatewayLogger:Python Tool successfully initialized\n",
      "INFO:AgentGatewayLogger:Python Tool successfully initialized\n",
      "INFO:AgentGatewayLogger:Cortex Search Tool successfully initialized\n",
      "INFO:AgentGatewayLogger:Cortex Analyst Tool successfully initialized\n",
      "INFO:AgentGatewayLogger:Python Tool successfully initialized\n",
      "INFO:AgentGatewayLogger:Cortex gateway successfully initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instrumenting <class 'agent_gateway.tools.snowflake_tools.CortexSearchTool'> for base <class 'agent_gateway.tools.snowflake_tools.CortexSearchTool'>\n",
      "\tinstrumenting __call__\n",
      "\tinstrumenting asearch\n",
      "instrumenting <class 'agent_gateway.tools.snowflake_tools.CortexAnalystTool'> for base <class 'agent_gateway.tools.snowflake_tools.CortexAnalystTool'>\n",
      "\tinstrumenting __call__\n",
      "\tinstrumenting asearch\n",
      "\tinstrumenting _process_analyst_message\n",
      "instrumenting <class 'agent_gateway.gateway.gateway.Agent'> for base <class 'agent_gateway.gateway.gateway.Agent'>\n",
      "\tinstrumenting fuse\n",
      "\tinstrumenting __call__\n",
      "\tinstrumenting handle_exception\n",
      "\tinstrumenting run_async\n",
      "\tinstrumenting acall\n",
      "instrumenting <class 'agent_gateway.gateway.planner.Planner'> for base <class 'agent_gateway.gateway.planner.Planner'>\n",
      "\tinstrumenting plan\n",
      "instrumenting <class 'agent_gateway.tools.snowflake_tools.CortexSearchTool'> for base <class 'agent_gateway.tools.snowflake_tools.CortexSearchTool'>\n",
      "\tinstrumenting __call__\n",
      "\tinstrumenting asearch\n",
      "instrumenting <class 'agent_gateway.tools.snowflake_tools.CortexSearchTool'> for base <class 'agent_gateway.tools.snowflake_tools.CortexSearchTool'>\n",
      "\tinstrumenting __call__\n",
      "\tinstrumenting asearch\n",
      "instrumenting <class 'agent_gateway.tools.snowflake_tools.CortexSearchTool'> for base <class 'agent_gateway.tools.snowflake_tools.CortexSearchTool'>\n",
      "\tinstrumenting __call__\n",
      "\tinstrumenting asearch\n",
      "instrumenting <class 'agent_gateway.tools.snowflake_tools.CortexAnalystTool'> for base <class 'agent_gateway.tools.snowflake_tools.CortexAnalystTool'>\n",
      "\tinstrumenting __call__\n",
      "\tinstrumenting asearch\n",
      "\tinstrumenting _process_analyst_message\n",
      "instrumenting <class 'agent_gateway.tools.snowflake_tools.CortexAnalystTool'> for base <class 'agent_gateway.tools.snowflake_tools.CortexAnalystTool'>\n",
      "\tinstrumenting __call__\n",
      "\tinstrumenting asearch\n",
      "\tinstrumenting _process_analyst_message\n",
      "instrumenting <class 'agent_gateway.gateway.gateway.CortexCompleteAgent'> for base <class 'agent_gateway.gateway.gateway.CortexCompleteAgent'>\n",
      "\tinstrumenting arun\n",
      "\tinstrumenting _prepare_llm_request\n",
      "\tinstrumenting _parse_snowflake_response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:trulens.apps.app:Function <function Task.__call__ at 0x14b15a5c0> was not found during instrumentation walk. Make sure it is accessible by traversing app name='gateway' memory=True verbose=False planner=<agent_gateway.gateway.planner.Planner object at 0x15b43a150> agent=<agent_gateway.gateway.gateway.CortexCompleteAgent object at 0x1059d3bd0> fusion_prompt=('You must solve the Question. You are given Observations and you can use them to solve the Question. Then you MUST provide a Thought, and then an Action. Do not use any parenthesis.\\nYou will be given a question either some passages or numbers, which are observations.\\n\\nThought step can reason about the observations in 1-2 sentences, and Action can be only one type:\\n (1) Finish(answer): returns the answer and finishes the task using information you found from observations. (2) Replan: returns the original user\\'s question and replans in order to get the information needed to answer the question.\\nFollow the guidelines that you will die if you don\\'t follow:\\n  - Answer should be directly answer the question.\\n  - Thought should be 1-2 sentences.\\n  - Action can only be Finish or Replan\\n  - Action should be Finish if you have enough information to answer the question\\n  - Action Should be Replan if you don\\'t have enough information to answer the question\\n  - You must say <END_OF_RESPONSE> at the end of your response.\\n\\n\\nHere are some examples:\\n\\nQuestion: What is the EBITDA of Berkshire Hathaway?\\ncortexanalyst(What is the EBITDA of Berkshire Hathaway?)\\nObservation:   SYMBOL                    SHORTNAME  START_DATE  END_DATE        EBITDA\\n0  BRK-B  Berkshire Hathaway Inc. New      413.72    413.72  107046002688\\nThought: Berkshire Hathaway\\'s latest EBITDA is $107,046,002,688, or $107 Billion.\\nAction: Finish(Berkshire\\'s latest EBITDA is $107 Billion.)\\n<END_OF_RESPONSE>\\n\\n\\nQuestion: What is the latest news about Berkshire Hathaway?\\nnewstool(Berkshire Hathaway)\\nObservation: \\'[{\\'uuid\\': \\'c177ede5-07a7-4f63-a3b7-52790c8fd08e\\', \\'title\\': \\'Berkshire Hathaway-berkshire Hathaway Inc -- Berkshire Says It Hâ€¦\\', \\'description\\': \\'BERKSHIRE HATHAWAY-BERKSHIRE HATHAWAY INC -- BERKSHIRE SAYS IT HAD $147.4 BLN OF CASH AND EQUIVALENTS AS OF JUNE 30...\\', \\'keywords\\': \\'Markets\\', \\'snippet\\': \"Berkshire Hathaway Inc. (Berkshire) is a holding company owning subsidiaries engaged in various business activities. Berkshire\\'s various business activities inc...', \"url': 'https://www.marketscreener.com/quote/stock/BERKSHIRE-HATHAWAY-INC-11915/news/BERKSHIRE-HATHAWAY-BERKSHIRE-HATHAWAY-INC-BERKSHIRE-SAYS-IT-H-8230-44531571/', 'image_url': 'https://www.marketscreener.com/images/twitter_MS_fdblanc.png', 'language': 'en', 'published_at': '2023-08-05T12:15:15.000000Z', 'source': 'marketscreener.com', 'categories': ['business'], 'relevance_score': 55.634586}, {'uuid': '56202cf0-38af-4a20-b411-994c92d8c7cd', 'title': 'Berkshire Hathaway Inc. (OTCMKTS:BRK-A) Major Shareholder Berkshire Hathaway Inc Acquires 716,355 Shares', 'description': 'Read Berkshire Hathaway Inc. (OTCMKTS:BRK-A) Major Shareholder Berkshire Hathaway Inc Acquires 716,355 Shares at ETF Daily News', 'keywords': 'Berkshire Hathaway, OTCMKTS:BRK-A, BRK-A, Financial Service, Insider Trading, Insider Trades, Stocks', 'snippet': 'Berkshire Hathaway Inc. (OTCMKTS:BRK-A â€“ Get Rating) major shareholder Berkshire Hathaway Inc bought 716,355 shares of Berkshire Hathaway stock in a transacti...', 'url': 'https://www.etfdailynews.com/2022/05/13/berkshire-hathaway-inc-otcmktsbrk-a-major-shareholder-berkshire-hathaway-inc-acquires-716355-shares/', 'image_url': 'https://www.americanbankingnews.com/wp-content/timthumb/timthumb.php?src=https://www.marketbeat.com/logos/berkshire-hathaway-inc-logo.png?v=20211203153558&w=240&h=240&zc=2', 'language': 'en', 'published_at': '2022-05-13T11:18:50.000000Z', 'source': 'etfdailynews.com', 'categories': ['business'], 'relevance_score': 53.612434}]\\nThought: The recent news about Berkshire Hathaway include information about its financials and recent activities.\\nAction: Finish('Recent news about Berkshire Hathaways includes:\\n- Article: Berkshire Hathaway-Berkshire Hathaway Inc -- Berkshire Says It Hâ€¦  Source: [Market Screener](https://www.marketscreener.com/quote/stock/BERKSHIRE-HATHAWAY-INC-11915/news/BERKSHIRE-HATHAWAY-BERKSHIRE-HATHAWAY-INC-BERKSHIRE-SAYS-IT-H-8230-44531571/) \\n - Article: Berkshire Hathaway Inc. (OTCMKTS:BRK-A) Major Shareholder Berkshire Hathaway Inc Acquires 716,355 Shares' Source: [ETF Daily News](https://www.etfdailynews.com/2022/05/13/berkshire-hathaway-inc-otcmktsbrk-a-major-shareholder-berkshire-hathaway-inc-acquires-716355-shares/)) '\\n<END_OF_RESPONSE>\\n\\n\\nQuestion: How many queries are processed on Snowflake's platform?\\ncortexsearch(How many queries are processed on Snowflake's platform?)\\nObservation: ['deliver the Data Cloud, enabling a consistent, global user experience.\\nOur platform supports a wide range of workloads that enable our customersâ€™ most important business objectives, including data warehousing, data lakes, data engineering, data\\nscience, data application development, and data sharing. From January 1, 2022 to January 31, 2022, we processed an average of over 1,496 million daily queries across all of our\\ncustomer accounts, up from an average of over 777 million daily queries during the corresponding month of the prior fiscal year. We also recently launched our Powered by\\nSnowflake program to help companies build, operate, and grow applications in the Data Cloud by supporting developers across all stages of the application journey. Members of the\\nprogram have access to go-to-market, customer support, and engineering expertise.\\nWe have an industry-vertical focus, which allows us to go to market with tailored business solutions. For example, we have launched the Financial Services Data Cloud, the\\nMedia Data Cloud, the Healthcare and Life Sciences Data Cloud, and the Retail Data Cloud. Each of these Data Clouds brings together Snowflakeâ€™s platform capabilities with\\nindustry-specific partner solutions and datasets to drive business growth and deliver improved experiences and insights.\\nOur business benefits from powerful network effects. The Data Cloud will continue to grow as organizations move their siloed data from cloud-based repositories and on-\\npremises data centers to the Data Cloud. The more customers adopt our platform, the more data can be exchanged with other Snowflake customers, partners, data providers, and\\ndata consumers, enhancing the value of our platform for all users. We believe this network effect will help us drive our vision of the Data Cloud.\\n75/14/24, 8:55 AM snow-20220131\\nhttps://www.sec.gov/Archives/edgar/data/1640147/000164014722000023/snow-20220131.htm 8/183Table of Contents','the Data Cloud, enabling a consistent, global user experience.\\nOur platform supports a wide range of workloads that enable our customersâ€™ most important business objectives, including data warehouse, data lake, data engineering, AI/ML,\\napplications, collaboration, cybersecurity and Unistore. From January 1, 2024 to January 31, 2024, we processed an average of approximately 4.2 billion daily queries across all our\\ncustomer accounts, up from an average of approximately 2.6 billion daily queries during the corresponding month of the prior fiscal year. We are committed to expanding our\\nplatformâ€™s use cases and supporting developers in building their applications and businesses. In 2021, we launched Snowpark for Java and Scala to allow developers to build in the\\nlanguage of their choice, and in 2022 we added support for Python. In 2023, we launched Snowpark Container Services, a fully managed container platform designed to facilitate\\nthe deployment, management, and scaling of containerized applications and AI/ML models within our ecosystem. We continue to invest in our Native Application program to help\\ncompanies build, operate, and market applications in the Data Cloud by supporting developers across all stages of the application journey.\\nWe have an industry-vertical focus, which allows us to go to market with tailored business solutions. For example, we have launched the Telecom Data Cloud, the Financial\\nServices Data Cloud, the Media Data Cloud, the Healthcare and Life Sciences Data Cloud, and the Retail Data Cloud. Each of these brings together Snowflakeâ€™s platform\\ncapabilities with industry-specific partner solutions and datasets to drive business growth and deliver improved experiences and insights.\\nOur business benefits from powerful network effects. The Data Cloud will continue to grow as organizations move their siloed data from cloud-based repositories and on-','Our cloud-native architecture consists of three independently scalable but logically integrated layers across compute, storage, and cloud services. The compute layer provides\\ndedicated resources to enable users to simultaneously access common data sets for many use cases with minimal latency. The storage layer ingests massive amounts and varieties of\\nstructured, semi-structured, and unstructured data to create a unified data record. The cloud services layer intelligently optimizes each use caseâ€™s performance requirements with no\\nadministration. This architecture is built on three major public clouds across 38 regional deployments around the world. These deployments are generally interconnected to deliver\\nthe Data Cloud, enabling a consistent, global user experience.\\nOur platform supports a wide range of workloads that enable our customersâ€™ most important business objectives, including data warehousing, data lakes, and Unistore, as well\\nas collaboration, data engineering, cybersecurity, data science and machine learning, and application development. From January 1, 2023 to January 31, 2023, we processed an\\naverage of approximately 2.6 billion daily queries across all our customer accounts, up from an average of approximately 1.5 billion daily queries during the corresponding month\\nof the prior fiscal year. We are committed to expanding our platformâ€™s use cases and supporting developers in building their applications and businesses. In 2021, we launched\\nSnowpark for Java to allow developers to build in the language of their choice, and in 2022 we added support for Python. We continue to invest in our Powered by Snowflake\\nprogram to help companies build, operate, and market applications in the Data Cloud by supporting developers across all stages of the application journey. As of January 31, 2023,\\nwe had over 820 Powered by Snowflake registrants. Powered by Snowflake partners have access to go-to-market, customer support, and engineering expertise.','performance comparable to a relational, structured representation.\\nâ€¢Query Capabilities. Our platform is engineered to query petabytes of data. It implements support for a large subset of the ANSI SQL standard for read operations and data\\nmodification operations. Our platform provides additional features, including:\\nâ—¦Time travel. Our platform keeps track of all changes happening to a table, which enables customers to query previous versions based on their preferences. Customers\\ncan query as of a relative point in time or as of an absolute point in time. This has a broad array of use cases for customers, including error recovery, time-based\\nanalysis, and data quality checks.5/14/24, 8:59 AM snow-20210131\\nhttps://www.sec.gov/Archives/edgar/data/1640147/000164014721000073/snow-20210131.htm 17/193â—¦ Cloning. Our architecture enables us to offer zero-copy cloning, an operation by which entire tables, schemas, or databases can be duplicatedâ€”or clonedâ€”without\\nhaving to copy or duplicate the underlying data. Our platform leverages the separation between cloud services and storage to be able to track independent clones of\\nobjects sharing the same physical copy of the underlying data. This enables a variety of customer use cases such as making copies of production data for data\\nscientists, creating custom snapshots in time, or testing data pipelines.\\n105/14/24, 8:59 AM snow-20210131\\nhttps://www.sec.gov/Archives/edgar/data/1640147/000164014721000073/snow-20210131.htm 18/193Table of Contents\\nâ€¢Compute Model. Our platform offers a variety of capabilities to operate on data, from ingestion to transformation, as well as rich query and analysis. Our compute services\\nare primarily presented to users in one of two models, either through explicit specification of compute clusters we call virtual warehouses or through a number of serverless\\nservices.','performance.\\nâ—¦ Metadata. When data is ingested, our platform automatically extracts and stores metadata to speed up query processing. It does so by collecting data distribution\\ninformation for all columns in every micro-partition.5/14/24, 8:55 AM snow-20240131\\nhttps://www.sec.gov/Archives/edgar/data/1640147/000164014724000101/snow-20240131.htm 20/217â—¦Semi-structured and unstructured data. In addition to structured, relational data, our platform supports semi-structured data, including JSON, Avro, and Parquet, and\\nunstructured data, including PDF documents, screenshots, recordings, and images. Data in these formats can be ingested and queried with performance comparable to a\\nrelational, structured representation.\\n135/14/24, 8:55 AM snow-20240131\\nhttps://www.sec.gov/Archives/edgar/data/1640147/000164014724000101/snow-20240131.htm 21/217Table of Contents\\nâ€¢Query Capabilities. Our platform is engineered to query petabytes of data. It implements support for a large subset of the ANSI SQL standard for read operations and data\\nmodification operations. Our platform provides additional features, including:\\nâ—¦Time travel. Our platform keeps track of all changes happening to a table, which enables customers to query previous versions based on their preferences. Customers\\ncan query as of a relative point in time or as of an absolute point in time. This has a broad array of use cases for customers, including error recovery, time-based\\nanalysis, and data quality checks.\\nâ—¦ Cloning. Our architecture enables us to offer zero-copy cloning, an operation by which entire tables, schemas, or databases can be duplicatedâ€”or clonedâ€”without\\nhaving to copy or duplicate the underlying data. Our platform leverages the separation between cloud services and storage to be able to track independent clones of\\nobjects sharing the same physical copy of the underlying data. This enables a variety of customer use cases such as making copies of production data for data']Thought: Berkshire Hathaway's latest EBITDA is $107,046,002,688, or $107 Billion.\\nAction: Finish(Based on January 2024 data, Snowflake processes an average of approximately 4.2 billion daily queries across all customer account. This is an increase up from an average of approximately 2.6 billion daily queries during the corresponding month of the prior year.)\\n<END_OF_RESPONSE>\\n\\n\\n\") fusion_prompt_final=('You must solve the Question. You are given Observations and you can use them to solve the Question. Then you MUST provide a Thought, and then an Action. Do not use any parenthesis.\\nYou will be given a question either some passages or numbers, which are observations.\\n\\nThought step can reason about the observations in 1-2 sentences, and Action can be only one type:\\n (1) Finish(answer): returns the answer and finishes the task using information you found from observations. (2) Replan: returns the original user\\'s question and replans in order to get the information needed to answer the question.\\nFollow the guidelines that you will die if you don\\'t follow:\\n  - Answer should be directly answer the question.\\n  - Thought should be 1-2 sentences.\\n  - Action can only be Finish or Replan\\n  - Action should be Finish if you have enough information to answer the question\\n  - Action Should be Replan if you don\\'t have enough information to answer the question\\n  - You must say <END_OF_RESPONSE> at the end of your response.\\n\\n\\nHere are some examples:\\n\\nQuestion: What is the EBITDA of Berkshire Hathaway?\\ncortexanalyst(What is the EBITDA of Berkshire Hathaway?)\\nObservation:   SYMBOL                    SHORTNAME  START_DATE  END_DATE        EBITDA\\n0  BRK-B  Berkshire Hathaway Inc. New      413.72    413.72  107046002688\\nThought: Berkshire Hathaway\\'s latest EBITDA is $107,046,002,688, or $107 Billion.\\nAction: Finish(Berkshire\\'s latest EBITDA is $107 Billion.)\\n<END_OF_RESPONSE>\\n\\n\\nQuestion: What is the latest news about Berkshire Hathaway?\\nnewstool(Berkshire Hathaway)\\nObservation: \\'[{\\'uuid\\': \\'c177ede5-07a7-4f63-a3b7-52790c8fd08e\\', \\'title\\': \\'Berkshire Hathaway-berkshire Hathaway Inc -- Berkshire Says It Hâ€¦\\', \\'description\\': \\'BERKSHIRE HATHAWAY-BERKSHIRE HATHAWAY INC -- BERKSHIRE SAYS IT HAD $147.4 BLN OF CASH AND EQUIVALENTS AS OF JUNE 30...\\', \\'keywords\\': \\'Markets\\', \\'snippet\\': \"Berkshire Hathaway Inc. (Berkshire) is a holding company owning subsidiaries engaged in various business activities. Berkshire\\'s various business activities inc...', \"url': 'https://www.marketscreener.com/quote/stock/BERKSHIRE-HATHAWAY-INC-11915/news/BERKSHIRE-HATHAWAY-BERKSHIRE-HATHAWAY-INC-BERKSHIRE-SAYS-IT-H-8230-44531571/', 'image_url': 'https://www.marketscreener.com/images/twitter_MS_fdblanc.png', 'language': 'en', 'published_at': '2023-08-05T12:15:15.000000Z', 'source': 'marketscreener.com', 'categories': ['business'], 'relevance_score': 55.634586}, {'uuid': '56202cf0-38af-4a20-b411-994c92d8c7cd', 'title': 'Berkshire Hathaway Inc. (OTCMKTS:BRK-A) Major Shareholder Berkshire Hathaway Inc Acquires 716,355 Shares', 'description': 'Read Berkshire Hathaway Inc. (OTCMKTS:BRK-A) Major Shareholder Berkshire Hathaway Inc Acquires 716,355 Shares at ETF Daily News', 'keywords': 'Berkshire Hathaway, OTCMKTS:BRK-A, BRK-A, Financial Service, Insider Trading, Insider Trades, Stocks', 'snippet': 'Berkshire Hathaway Inc. (OTCMKTS:BRK-A â€“ Get Rating) major shareholder Berkshire Hathaway Inc bought 716,355 shares of Berkshire Hathaway stock in a transacti...', 'url': 'https://www.etfdailynews.com/2022/05/13/berkshire-hathaway-inc-otcmktsbrk-a-major-shareholder-berkshire-hathaway-inc-acquires-716355-shares/', 'image_url': 'https://www.americanbankingnews.com/wp-content/timthumb/timthumb.php?src=https://www.marketbeat.com/logos/berkshire-hathaway-inc-logo.png?v=20211203153558&w=240&h=240&zc=2', 'language': 'en', 'published_at': '2022-05-13T11:18:50.000000Z', 'source': 'etfdailynews.com', 'categories': ['business'], 'relevance_score': 53.612434}]\\nThought: The recent news about Berkshire Hathaway include information about its financials and recent activities.\\nAction: Finish('Recent news about Berkshire Hathaways includes:\\n- Article: Berkshire Hathaway-Berkshire Hathaway Inc -- Berkshire Says It Hâ€¦  Source: [Market Screener](https://www.marketscreener.com/quote/stock/BERKSHIRE-HATHAWAY-INC-11915/news/BERKSHIRE-HATHAWAY-BERKSHIRE-HATHAWAY-INC-BERKSHIRE-SAYS-IT-H-8230-44531571/) \\n - Article: Berkshire Hathaway Inc. (OTCMKTS:BRK-A) Major Shareholder Berkshire Hathaway Inc Acquires 716,355 Shares' Source: [ETF Daily News](https://www.etfdailynews.com/2022/05/13/berkshire-hathaway-inc-otcmktsbrk-a-major-shareholder-berkshire-hathaway-inc-acquires-716355-shares/)) '\\n<END_OF_RESPONSE>\\n\\n\\nQuestion: How many queries are processed on Snowflake's platform?\\ncortexsearch(How many queries are processed on Snowflake's platform?)\\nObservation: ['deliver the Data Cloud, enabling a consistent, global user experience.\\nOur platform supports a wide range of workloads that enable our customersâ€™ most important business objectives, including data warehousing, data lakes, data engineering, data\\nscience, data application development, and data sharing. From January 1, 2022 to January 31, 2022, we processed an average of over 1,496 million daily queries across all of our\\ncustomer accounts, up from an average of over 777 million daily queries during the corresponding month of the prior fiscal year. We also recently launched our Powered by\\nSnowflake program to help companies build, operate, and grow applications in the Data Cloud by supporting developers across all stages of the application journey. Members of the\\nprogram have access to go-to-market, customer support, and engineering expertise.\\nWe have an industry-vertical focus, which allows us to go to market with tailored business solutions. For example, we have launched the Financial Services Data Cloud, the\\nMedia Data Cloud, the Healthcare and Life Sciences Data Cloud, and the Retail Data Cloud. Each of these Data Clouds brings together Snowflakeâ€™s platform capabilities with\\nindustry-specific partner solutions and datasets to drive business growth and deliver improved experiences and insights.\\nOur business benefits from powerful network effects. The Data Cloud will continue to grow as organizations move their siloed data from cloud-based repositories and on-\\npremises data centers to the Data Cloud. The more customers adopt our platform, the more data can be exchanged with other Snowflake customers, partners, data providers, and\\ndata consumers, enhancing the value of our platform for all users. We believe this network effect will help us drive our vision of the Data Cloud.\\n75/14/24, 8:55 AM snow-20220131\\nhttps://www.sec.gov/Archives/edgar/data/1640147/000164014722000023/snow-20220131.htm 8/183Table of Contents','the Data Cloud, enabling a consistent, global user experience.\\nOur platform supports a wide range of workloads that enable our customersâ€™ most important business objectives, including data warehouse, data lake, data engineering, AI/ML,\\napplications, collaboration, cybersecurity and Unistore. From January 1, 2024 to January 31, 2024, we processed an average of approximately 4.2 billion daily queries across all our\\ncustomer accounts, up from an average of approximately 2.6 billion daily queries during the corresponding month of the prior fiscal year. We are committed to expanding our\\nplatformâ€™s use cases and supporting developers in building their applications and businesses. In 2021, we launched Snowpark for Java and Scala to allow developers to build in the\\nlanguage of their choice, and in 2022 we added support for Python. In 2023, we launched Snowpark Container Services, a fully managed container platform designed to facilitate\\nthe deployment, management, and scaling of containerized applications and AI/ML models within our ecosystem. We continue to invest in our Native Application program to help\\ncompanies build, operate, and market applications in the Data Cloud by supporting developers across all stages of the application journey.\\nWe have an industry-vertical focus, which allows us to go to market with tailored business solutions. For example, we have launched the Telecom Data Cloud, the Financial\\nServices Data Cloud, the Media Data Cloud, the Healthcare and Life Sciences Data Cloud, and the Retail Data Cloud. Each of these brings together Snowflakeâ€™s platform\\ncapabilities with industry-specific partner solutions and datasets to drive business growth and deliver improved experiences and insights.\\nOur business benefits from powerful network effects. The Data Cloud will continue to grow as organizations move their siloed data from cloud-based repositories and on-','Our cloud-native architecture consists of three independently scalable but logically integrated layers across compute, storage, and cloud services. The compute layer provides\\ndedicated resources to enable users to simultaneously access common data sets for many use cases with minimal latency. The storage layer ingests massive amounts and varieties of\\nstructured, semi-structured, and unstructured data to create a unified data record. The cloud services layer intelligently optimizes each use caseâ€™s performance requirements with no\\nadministration. This architecture is built on three major public clouds across 38 regional deployments around the world. These deployments are generally interconnected to deliver\\nthe Data Cloud, enabling a consistent, global user experience.\\nOur platform supports a wide range of workloads that enable our customersâ€™ most important business objectives, including data warehousing, data lakes, and Unistore, as well\\nas collaboration, data engineering, cybersecurity, data science and machine learning, and application development. From January 1, 2023 to January 31, 2023, we processed an\\naverage of approximately 2.6 billion daily queries across all our customer accounts, up from an average of approximately 1.5 billion daily queries during the corresponding month\\nof the prior fiscal year. We are committed to expanding our platformâ€™s use cases and supporting developers in building their applications and businesses. In 2021, we launched\\nSnowpark for Java to allow developers to build in the language of their choice, and in 2022 we added support for Python. We continue to invest in our Powered by Snowflake\\nprogram to help companies build, operate, and market applications in the Data Cloud by supporting developers across all stages of the application journey. As of January 31, 2023,\\nwe had over 820 Powered by Snowflake registrants. Powered by Snowflake partners have access to go-to-market, customer support, and engineering expertise.','performance comparable to a relational, structured representation.\\nâ€¢Query Capabilities. Our platform is engineered to query petabytes of data. It implements support for a large subset of the ANSI SQL standard for read operations and data\\nmodification operations. Our platform provides additional features, including:\\nâ—¦Time travel. Our platform keeps track of all changes happening to a table, which enables customers to query previous versions based on their preferences. Customers\\ncan query as of a relative point in time or as of an absolute point in time. This has a broad array of use cases for customers, including error recovery, time-based\\nanalysis, and data quality checks.5/14/24, 8:59 AM snow-20210131\\nhttps://www.sec.gov/Archives/edgar/data/1640147/000164014721000073/snow-20210131.htm 17/193â—¦ Cloning. Our architecture enables us to offer zero-copy cloning, an operation by which entire tables, schemas, or databases can be duplicatedâ€”or clonedâ€”without\\nhaving to copy or duplicate the underlying data. Our platform leverages the separation between cloud services and storage to be able to track independent clones of\\nobjects sharing the same physical copy of the underlying data. This enables a variety of customer use cases such as making copies of production data for data\\nscientists, creating custom snapshots in time, or testing data pipelines.\\n105/14/24, 8:59 AM snow-20210131\\nhttps://www.sec.gov/Archives/edgar/data/1640147/000164014721000073/snow-20210131.htm 18/193Table of Contents\\nâ€¢Compute Model. Our platform offers a variety of capabilities to operate on data, from ingestion to transformation, as well as rich query and analysis. Our compute services\\nare primarily presented to users in one of two models, either through explicit specification of compute clusters we call virtual warehouses or through a number of serverless\\nservices.','performance.\\nâ—¦ Metadata. When data is ingested, our platform automatically extracts and stores metadata to speed up query processing. It does so by collecting data distribution\\ninformation for all columns in every micro-partition.5/14/24, 8:55 AM snow-20240131\\nhttps://www.sec.gov/Archives/edgar/data/1640147/000164014724000101/snow-20240131.htm 20/217â—¦Semi-structured and unstructured data. In addition to structured, relational data, our platform supports semi-structured data, including JSON, Avro, and Parquet, and\\nunstructured data, including PDF documents, screenshots, recordings, and images. Data in these formats can be ingested and queried with performance comparable to a\\nrelational, structured representation.\\n135/14/24, 8:55 AM snow-20240131\\nhttps://www.sec.gov/Archives/edgar/data/1640147/000164014724000101/snow-20240131.htm 21/217Table of Contents\\nâ€¢Query Capabilities. Our platform is engineered to query petabytes of data. It implements support for a large subset of the ANSI SQL standard for read operations and data\\nmodification operations. Our platform provides additional features, including:\\nâ—¦Time travel. Our platform keeps track of all changes happening to a table, which enables customers to query previous versions based on their preferences. Customers\\ncan query as of a relative point in time or as of an absolute point in time. This has a broad array of use cases for customers, including error recovery, time-based\\nanalysis, and data quality checks.\\nâ—¦ Cloning. Our architecture enables us to offer zero-copy cloning, an operation by which entire tables, schemas, or databases can be duplicatedâ€”or clonedâ€”without\\nhaving to copy or duplicate the underlying data. Our platform leverages the separation between cloud services and storage to be able to track independent clones of\\nobjects sharing the same physical copy of the underlying data. This enables a variety of customer use cases such as making copies of production data for data']Thought: Berkshire Hathaway's latest EBITDA is $107,046,002,688, or $107 Billion.\\nAction: Finish(Based on January 2024 data, Snowflake processes an average of approximately 4.2 billion daily queries across all customer account. This is an increase up from an average of approximately 2.6 billion daily queries during the corresponding month of the prior year.)\\n<END_OF_RESPONSE>\\n\\n\\n\") planner_stream=False max_retries=2 memory_context=[] planner_callback=None executor_callback=None or provide a bound method for it as TruApp constructor argument `methods_to_instrument`.\n"
     ]
    }
   ],
   "source": [
    "topic_search = CortexSearchTool(**topic_search_config)\n",
    "domain_search = CortexSearchTool(**domain_search_config)\n",
    "case_search = CortexSearchTool(**case_search_config)\n",
    "ride_analyst = CortexAnalystTool(**ride_analyst_config)\n",
    "support_ticket_analyst = CortexAnalystTool(**support_ticket_analyst_config)\n",
    "news_search = PythonTool(**news_python_config)\n",
    "web_crawler = PythonTool(**python_crawler_config)\n",
    "snowflake_tools = [topic_search, domain_search, case_search, ride_analyst, support_ticket_analyst, news_search, web_crawler]\n",
    "#agent = Agent(snowflake_connection=snowpark, tools=snowflake_tools, max_retries=3)\n",
    "agent = TruAgent(app_name=\"trulens_orchestration_framework\",app_version=\"v0.1\",trulens_snowflake_connection=conn,tools=snowflake_tools,snowflake_connection=snowpark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 types of questions below are designed to showcase the breadth of tool use patterns possible with the Agent Gateway. \n",
    "\n",
    "- The Structured Data Questions use the Cortex Analyst agent. \n",
    "- The Unstructured Data Questions use either the Cortex Search agent or the Python (News API) agent.\n",
    "- The last section includes a question that requires the use of both types of tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:AgentGatewayLogger:running rides_cortexanalyst task\n",
      "INFO:AgentGatewayLogger:running support_tickets_cortexanalyst task\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In 2024, we gave a total of 19,367,782 rides and received 86,934 customer support tickets.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"how many total rides did we give in 2024 ? And how many total customer support tickets did we receive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:AgentGatewayLogger:running news_search task\n",
      "INFO:AgentGatewayLogger:running case_search_cortexsearch task\n",
      "INFO:AgentGatewayLogger:running news_search task\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Yes, there are recent news articles about Lyft facing safety problems. For example, Lyft reached a $25 million settlement over claims it hid safety problems. Additionally, there are support cases where users report similar safety issues, such as Ticket IDs 'fad18c70-0ff3-4786-9caa-21ce3fabb8a7' and 'b53e3eaa-1008-47d5-af1a-d8f377cbbb2c'.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"Are Uber and Lyft customers complaining about any safety problems in recent news ? Can you give me a couple of examples in our support cases where users are reporting similar events ? Ensure you include the Ticket IDs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:AgentGatewayLogger:running rides_cortexanalyst task\n",
      "INFO:AgentGatewayLogger:running case_search_cortexsearch task\n",
      "INFO:AgentGatewayLogger:running summarize task\n",
      "ERROR:AgentGatewayLogger:Your request is unclear. Consider rephrasing your request to one of the following suggestions:['How much did the customer with customer_id: c6837d8800ef3d61653a8e79ff0ea7b2 spend on rides?', 'How much did the customer with customer_id: 5d31b3ea1ad2b747896293a4a96c99ef spend on rides?', 'How much did the customer with customer_id: faeabf1ce5471a9be6366803792eeb31 spend on rides?']\n",
      "ERROR:AgentGatewayLogger:{'content': [{'text': 'I apologize, but I cannot find a customer with the '\n",
      "                      'specified Ticket ID '\n",
      "                      \"'fad18c70-0ff3-4786-9caa-21ce3fabb8a7' in the semantic \"\n",
      "                      'model. The model uses customer_id to identify '\n",
      "                      'customers, not Ticket ID. If you could provide a valid '\n",
      "                      'customer_id, I would be able to calculate their total '\n",
      "                      'ride spending.',\n",
      "              'type': 'text'},\n",
      "             {'suggestions': ['How much did the customer with customer_id: '\n",
      "                              'c6837d8800ef3d61653a8e79ff0ea7b2 spend on '\n",
      "                              'rides?',\n",
      "                              'How much did the customer with customer_id: '\n",
      "                              '5d31b3ea1ad2b747896293a4a96c99ef spend on '\n",
      "                              'rides?',\n",
      "                              'How much did the customer with customer_id: '\n",
      "                              'faeabf1ce5471a9be6366803792eeb31 spend on '\n",
      "                              'rides?'],\n",
      "              'type': 'suggestions'}],\n",
      " 'role': 'analyst'}\n",
      "INFO:AgentGatewayLogger:running support_tickets_cortexanalyst task\n",
      "INFO:AgentGatewayLogger:running case_search_cortexsearch task\n",
      "INFO:AgentGatewayLogger:running summarize task\n",
      "ERROR:AgentGatewayLogger:Your request is unclear. Consider rephrasing your request to one of the following suggestions:['For the customer associated with Ticket ID: fad18c70-0ff3-4786-9caa-21ce3fabb8a7, how many support tickets have they submitted?', 'What is the average case life time in days for all tickets submitted by the customer with Ticket ID: fad18c70-0ff3-4786-9caa-21ce3fabb8a7?', 'What domains and features have support tickets been created for by the customer with Ticket ID: fad18c70-0ff3-4786-9caa-21ce3fabb8a7?']\n",
      "ERROR:AgentGatewayLogger:{'content': [{'text': 'I apologize, but I cannot answer this question using '\n",
      "                      'the given semantic model. While we have ticket_id '\n",
      "                      'information in the support_tickets_v table, there is no '\n",
      "                      'data about ride costs or spending amounts in the '\n",
      "                      'available schema. The model only contains support '\n",
      "                      'ticket related information like possession time, life '\n",
      "                      'time and health scores, but no financial data.',\n",
      "              'type': 'text'},\n",
      "             {'suggestions': ['For the customer associated with Ticket ID: '\n",
      "                              'fad18c70-0ff3-4786-9caa-21ce3fabb8a7, how many '\n",
      "                              'support tickets have they submitted?',\n",
      "                              'What is the average case life time in days for '\n",
      "                              'all tickets submitted by the customer with '\n",
      "                              'Ticket ID: '\n",
      "                              'fad18c70-0ff3-4786-9caa-21ce3fabb8a7?',\n",
      "                              'What domains and features have support tickets '\n",
      "                              'been created for by the customer with Ticket '\n",
      "                              'ID: fad18c70-0ff3-4786-9caa-21ce3fabb8a7?'],\n",
      "              'type': 'suggestions'}],\n",
      " 'role': 'analyst'}\n",
      "INFO:AgentGatewayLogger:running rides_cortexanalyst task\n",
      "INFO:AgentGatewayLogger:running case_search_cortexsearch task\n",
      "INFO:AgentGatewayLogger:running summarize task\n",
      "ERROR:AgentGatewayLogger:Your request is unclear. Consider rephrasing your request to one of the following suggestions:['How much did the customer with customer ID: c6837d8800ef3d61653a8e79ff0ea7b2 spend on rides?', 'How much did the customer who took ride ID: 674206a6-bc3c-46bf-819c-d6fa9c727373 spend on rides?', 'What is the total ride_cost for customer ID: 5d31b3ea1ad2b747896293a4a96c99ef?']\n",
      "ERROR:AgentGatewayLogger:{'content': [{'text': \"I apologize, but I notice you're asking about a \"\n",
      "                      'customer using a Ticket ID, however the semantic model '\n",
      "                      'only contains customer_id and ride_id fields. There is '\n",
      "                      'no ticket_id field available in the data model. To help '\n",
      "                      'you get the information you need, could you please '\n",
      "                      'provide either a customer_id or ride_id instead?',\n",
      "              'type': 'text'},\n",
      "             {'suggestions': ['How much did the customer with customer ID: '\n",
      "                              'c6837d8800ef3d61653a8e79ff0ea7b2 spend on '\n",
      "                              'rides?',\n",
      "                              'How much did the customer who took ride ID: '\n",
      "                              '674206a6-bc3c-46bf-819c-d6fa9c727373 spend on '\n",
      "                              'rides?',\n",
      "                              'What is the total ride_cost for customer ID: '\n",
      "                              '5d31b3ea1ad2b747896293a4a96c99ef?'],\n",
      "              'type': 'suggestions'}],\n",
      " 'role': 'analyst'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'How much did the customer with Ticket ID: fad18c70-0ff3-4786-9caa-21ce3fabb8a7 spend on rides? Unable to respond to your request with the available tools.  Consider rephrasing your request or providing additional tools.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\n",
    "    \"Give me a few bullets with details about the case with Ticket ID: fad18c70-0ff3-4786-9caa-21ce3fabb8a7. Also tell me how much the customer mentioned in the ticket as spent on rides.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orchestration_framework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
